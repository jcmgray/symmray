{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3fa9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "\n",
    "import symmray as sr\n",
    "\n",
    "Lx = 8\n",
    "Ly = 8\n",
    "nsites = Lx * Ly\n",
    "D = 8\n",
    "chi = D\n",
    "seed = 42\n",
    "# only the flat backend is compatible with jax.jit\n",
    "flat = True\n",
    "\n",
    "# batchsize\n",
    "B = 1024\n",
    "\n",
    "peps = sr.networks.PEPS_fermionic_rand(\n",
    "    \"Z2\",\n",
    "    Lx,\n",
    "    Ly,\n",
    "    D,\n",
    "    phys_dim=[\n",
    "        (0, 0),  # linear index 0 -> charge 0, offset 0\n",
    "        (1, 1),  # linear index 1 -> charge 1, offset 1\n",
    "        (1, 0),  # linear index 2 -> charge 1, offset 0\n",
    "        (0, 1),  # linear index 3 -> charge 0, offset 1\n",
    "    ],\n",
    "    subsizes=\"equal\",\n",
    "    flat=flat,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad705041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pytree of initial parameters, and reference tn structure\n",
    "params, skeleton = qtn.pack(peps)\n",
    "\n",
    "\n",
    "def amplitude(x, params):\n",
    "    tn = qtn.unpack(params, skeleton)\n",
    "\n",
    "    # might need to specify the right site ordering here\n",
    "    tnx = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "\n",
    "    return tnx.contract_hotrg(\n",
    "        max_bond=chi,\n",
    "        cutoff=0.0,\n",
    "        # these two options make the return value (mantissa, exponent)\n",
    "        # which can avoid issues with small/large values and stability\n",
    "        equalize_norms=1.0,\n",
    "        final_contract_opts=dict(strip_exponent=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6271bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate half-filling configs\n",
    "rng = np.random.default_rng(seed)\n",
    "xs = np.concatenate(\n",
    "    [\n",
    "        np.zeros((B, nsites // 2), dtype=np.int32),\n",
    "        np.ones((B, nsites // 2), dtype=np.int32),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "xs = rng.permuted(xs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc022d8",
   "metadata": {},
   "source": [
    "First test non eager version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fe90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 32.66959439764813\n"
     ]
    }
   ],
   "source": [
    "mantissa, exponent = amplitude(xs[0], params)\n",
    "print(mantissa, exponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc6518",
   "metadata": {},
   "source": [
    "Then test version with torch, gpu tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087dcfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.set_default_device(\"cuda:0\")\n",
    "\n",
    "# convert bitstrings and arrays to torch\n",
    "xs = torch.tensor(xs)\n",
    "params = qu.tree_map(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float32),\n",
    "    params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c464bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92 s ± 34.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mantissa, exponent = amplitude(xs[0], params)\n",
    "mantissa, exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d874eff",
   "metadata": {},
   "source": [
    "Then test and warm up torch vmapped version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a602837",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = torch.vmap(\n",
    "    amplitude,\n",
    "    # batch on configs, not parameters\n",
    "    in_dims=(0, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba03988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.12 s, sys: 28.1 ms, total: 4.15 s\n",
      "Wall time: 4.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 1., -1.,  1.,  ..., -1.,  1., -1.], device='cuda:0'),\n",
       " tensor([32.6688, 32.7025, 32.7157,  ..., 32.2940, 32.6343, 32.9307],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# warmup time\n",
    "vf(xs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946fc06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.93 s ± 244 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# final time (to compute full batch)\n",
    "vf(xs, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a6672",
   "metadata": {},
   "source": [
    "## Using `torch.nn.Module`\n",
    "\n",
    "Here we wrap the pure function in as a torch module, this enables various\n",
    "functionality, such as training and exporting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8bd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNAmplitudeModel(torch.nn.Module):\n",
    "    def __init__(self, fn, tn, vmap=False, **kwargs):\n",
    "        import quimb as qu\n",
    "        import quimb.tensor as qtn\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # split into plain arrays and bare tn structure\n",
    "        params, skeleton = qtn.pack(tn)\n",
    "        # for torch, further flatten pytree into a single list\n",
    "        params_flat, params_pytree = qu.utils.tree_flatten(\n",
    "            params, get_ref=True\n",
    "        )\n",
    "        # register the flat list parameters\n",
    "        self.params = torch.nn.ParameterList([\n",
    "            torch.as_tensor(x, dtype=torch.float32) for x in params_flat\n",
    "        ])\n",
    "\n",
    "        def amplitude(x):\n",
    "            params = qu.utils.tree_unflatten(self.params, params_pytree)\n",
    "            tn = qtn.unpack(params, skeleton)\n",
    "            return fn(x, tn, **kwargs)\n",
    "\n",
    "        if vmap:\n",
    "            self.f = torch.vmap(amplitude)\n",
    "        else:\n",
    "            self.f = amplitude\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return self.f(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ceb4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = TNAmplitudeModel(amplitude, peps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36326c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1., device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(32.6688, device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute output, with gradients\n",
    "model.forward(xs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb22a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1., device='cuda:0'), tensor(32.6688, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# compute output, no gradients\n",
    "with torch.inference_mode():\n",
    "    print(model.forward(xs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f0c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a vmapped model\n",
    "vmodel = TNAmplitudeModel(amplitude, peps, vmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d96ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 1., -1.,  1.,  ..., -1.,  1., -1.], device='cuda:0'), tensor([32.6688, 32.7025, 32.7157,  ..., 32.2940, 32.6343, 32.9307],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# compute batch output, no gradients\n",
    "with torch.inference_mode():\n",
    "    print(vmodel.forward(xs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
